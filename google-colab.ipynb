# --- INSTALL DEPENDENCIES ---
!pip install -q fastapi uvicorn pyngrok python-multipart soundfile numpy torch openai-whisper
!pip install -q git+https://github.com/hexgrad/kokoro.git

# --- IMPORTS ---
import os
import threading
import uvicorn
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import FileResponse
from pyngrok import ngrok
import soundfile as sf
import numpy as np
import torch
import whisper
from kokoro import KPipeline

# --- SETUP MODELS ---
app = FastAPI()

print("Loading Kokoro...")
pipeline = KPipeline(lang_code='a') 

print("Loading Whisper...")
whisper_model = whisper.load_model("base")

PAUSE_DURATION = 0.2

# --- HELPER FUNCTION ---
def generate_with_metrics(text, speed_factor):
    # Generates audio and counts segments for pause calculation
    generator = pipeline(text, voice='af_heart', speed=speed_factor, split_pattern=r'\n+')
    pieces = []
    segment_count = 0
    for _, _, audio in generator:
        if audio is not None and len(audio) > 0:
            pieces.append(np.array(audio, dtype=np.float32))
            # Add pause
            pieces.append(np.zeros(int(24000 * PAUSE_DURATION), dtype=np.float32))
            segment_count += 1
    
    if not pieces:
        return np.array([], dtype=np.float32), 0
        
    return np.concatenate(pieces), segment_count

# --- API ENDPOINTS ---

@app.get("/")
def read_root():
    return {"status": "Smart Speed Server is Running!"}

@app.post("/generate_audio")
def generate_audio(text: str = Form(...), target_duration: float = Form(...)):
    print(f"Received request: Text len={len(text)}, Target={target_duration}s")
    
    # --- PASS 1: MEASUREMENT ---
    raw_audio, seg_count = generate_with_metrics(text, 1.0)
    
    total_pause_time = seg_count * PAUSE_DURATION
    speech_len_p1 = (len(raw_audio) / 24000) - total_pause_time
    
    if speech_len_p1 <= 0:
        return {"error": "Script is empty or invalid"}

    # --- MATH CALCULATION ---
    # We remove pause time from target to find pure speech time needed
    target_speech_time = max(target_duration - total_pause_time, 1.0)
    
    # Calculate required speed
    raw_speed = speech_len_p1 / target_speech_time
    required_speed = float(raw_speed ** 0.90) # The magic formula
    
    # Clamp speed to be safe (Kokoro breaks if too fast/slow)
    required_speed = max(0.5, min(required_speed, 2.0))
    
    print(f"Adjusting speed: {required_speed:.2f}x")

    # --- PASS 2: GENERATION ---
    final_audio, _ = generate_with_metrics(text, required_speed)

    # --- EXACT TRIMMING/PADDING ---
    target_samples = int(target_duration * 24000)
    current_samples = len(final_audio)
    
    if current_samples < target_samples:
        # If too short, add silence at the end
        final_audio = np.pad(final_audio, (0, target_samples - current_samples))
    elif current_samples > target_samples:
        # If too long, trim the end
        final_audio = final_audio[:target_samples]
    
    # Save and Return
    output_path = "/content/generated.wav"
    sf.write(output_path, final_audio, 24000)
    
    return FileResponse(output_path, media_type="audio/wav", filename="generated.wav")

@app.post("/transcribe")
async def transcribe(file: UploadFile = File(...)):
    print("Transcribing...")
    temp_audio = f"/content/{file.filename}"
    with open(temp_audio, "wb") as buffer:
        buffer.write(await file.read())
    result = whisper_model.transcribe(temp_audio)
    return {"segments": result["segments"]}

# --- RUN SERVER ---
NGROK_TOKEN = "PASTE YOUR TOKEN HERE"  # <--- PASTE YOUR TOKEN HERE
ngrok.set_auth_token(NGROK_TOKEN)
public_url = ngrok.connect(8000).public_url
print(f"\nðŸš€ SMART SERVER READY! URL: {public_url}\n")

def run_server():
    uvicorn.run(app, host="0.0.0.0", port=8000)

server_thread = threading.Thread(target=run_server)
server_thread.start()